{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_lab_5_Logistic Classification",
      "provenance": [],
      "authorship_tag": "ABX9TyPB2sN0p+R/D2zAFzpUBlEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunjoo-ny/ML-Code/blob/main/Pytorch_lab_5_Logistic_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ET8BYu1Na2"
      },
      "source": [
        "Logistic Regression\n",
        "Hypothesis\n",
        "$$ H(X) = \\frac{1}{1+e^{-W^T X}} $$\n",
        "Cost\n",
        "$$ cost(W) = -\\frac{1}{m} \\sum y \\log\\left(H(x)\\right) + (1-y) \\left( \\log(1-H(x) \\right) $$\n",
        "If $y \\simeq H(x)$, cost is near 0.\n",
        "If $y \\neq H(x)$, cost is high.\n",
        "Weight Update via Gradient Descent\n",
        "$$ W := W - \\alpha \\frac{\\partial}{\\partial W} cost(W) $$\n",
        "$\\alpha$: Learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rljrq3M2CwpV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiIFfelPCwsL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3dyJxxs1ZF6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwgr2JBv1Zjg",
        "outputId": "16461dd3-dc12-40c1-dfde-1a766f3f6e2e"
      },
      "source": [
        "#for reproducibility\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f40e7e45b58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdyFMUVv1Zpq"
      },
      "source": [
        "x_data=[[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
        "y_data=[[0],[0],[0],[1],[1],[1]]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blt4FCPR2Olw"
      },
      "source": [
        "Consider the following classification problem: given the number of hours each student spent watching the lecture and working in the code lab, predict whether the student passed or failed a course. For example, the first (index 0) student watched the lecture for 1 hour and spent 2 hours in the lab session ([1, 2]), and ended up failing the course ([0])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JAiKdHf1Zvd"
      },
      "source": [
        "x_train=torch.FloatTensor(x_data)\n",
        "y_train=torch.FloatTensor(y_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-_RXC9x1Zy1",
        "outputId": "daf6f365-2f30-4022-82f8-caf00cfa0f71"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 2])\n",
            "torch.Size([6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wenVImhe5EAD"
      },
      "source": [
        "Computing the Hypothesis\n",
        "$$ H(X) = \\frac{1}{1+e^{-W^T X}} $$\n",
        "PyTorch has a torch.exp() function that resembles the exponential function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHOIE0c71Z1v"
      },
      "source": [
        "W=torch.zeros((2,1),requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8leWAmF5cps",
        "outputId": "98981164-385b-4bd1-c2df-3b6e2d95ff35"
      },
      "source": [
        "hypothesis=1/(1+torch.exp(-(x_train.matmul(W)+b)))\n",
        "hypothesis,hypothesis.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5000],\n",
              "         [0.5000],\n",
              "         [0.5000],\n",
              "         [0.5000],\n",
              "         [0.5000],\n",
              "         [0.5000]], grad_fn=<MulBackward0>), torch.Size([6, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN5abXiJ5csu",
        "outputId": "b178d53e-c09d-42e3-a1b5-4b7d656960ba"
      },
      "source": [
        "hypothesis1=torch.sigmoid(x_train.matmul(W)+b)\n",
        "hypothesis1,hypothesis1.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5000],\n",
              "         [0.5000],\n",
              "         [0.5000],\n",
              "         [0.5000],\n",
              "         [0.5000],\n",
              "         [0.5000]], grad_fn=<SigmoidBackward>), torch.Size([6, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjC3p32n7BHD"
      },
      "source": [
        "Computing the Cost Function (Low-level)\n",
        "$$ cost(W) = -\\frac{1}{m} \\sum y \\log\\left(H(x)\\right) + (1-y) \\left( \\log(1-H(x) \\right) $$\n",
        "We want to measure the difference between hypothesis and y_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PJMDdFg5cvj",
        "outputId": "4d4242f7-9f51-4aa6-997a-c46e60344e58"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3I1Uctx7J9R",
        "outputId": "93172e9d-965b-45c0-cd40-a52175cb2916"
      },
      "source": [
        "loss_0=-(y_train[0]*torch.log(hypothesis1[0])+(1-y_train[0])*torch.log(1-hypothesis1[0]))\n",
        "loss_0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6931], grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB03lH3A7KAN",
        "outputId": "0709f841-58fa-4153-97af-90d3166ceebe"
      },
      "source": [
        "losses=-(y_train*torch.log(hypothesis1)+(1-y_train)*torch.log(1-hypothesis1))\n",
        "print(losses)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931]], grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2CpCM_E7KDA",
        "outputId": "87372454-9431-41cc-b586-19a43845543e"
      },
      "source": [
        "cost=losses.mean()\n",
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27UpTp-R8LqW"
      },
      "source": [
        "Computing the Cost Function with F.binary_cross_entropy\n",
        "In reality, binary classification is used so often that PyTorch has a simple function called F.binary_cross_entropy implemented to lighten the burden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8WqiL1D7KLE",
        "outputId": "48b086df-75f8-459e-a8de-f546d4793e29"
      },
      "source": [
        "#This method is another way to get the cost\n",
        "F.binary_cross_entropy(hypothesis1,y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ach_tSrc7KQC"
      },
      "source": [
        "x_data=[[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
        "y_data=[[0],[0],[0],[1],[1],[1]]\n",
        "x_train=torch.FloatTensor(x_data)\n",
        "y_train=torch.FloatTensor(y_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBL2Gip55czp",
        "outputId": "657481a2-ade1-4cf6-ae6b-8d95562b2a81"
      },
      "source": [
        "#initialize the model\n",
        "W=torch.zeros((2,1),requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "#set the optimizer\n",
        "optimizer=optim.SGD([W,b],lr=1)\n",
        "#loop of the epochs\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "    \n",
        "#hypothesis and cost\n",
        "    hypothesis2=torch.sigmoid(x_train.matmul(W)+b)\n",
        "    cost=-(y_train*torch.log(hypothesis2)+(1-y_train)*torch.log(1-hypothesis2)).mean()\n",
        "#the improvement of the cost into H(x)\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "#print per 100 \n",
        "    if epoch%100==0:\n",
        "       print('Epoch:{:4d}/{},Cost:{:.6f}'.format(epoch,nb_epochs,cost.item()))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0/1000,Cost:0.693147\n",
            "Epoch: 100/1000,Cost:0.134722\n",
            "Epoch: 200/1000,Cost:0.080643\n",
            "Epoch: 300/1000,Cost:0.057900\n",
            "Epoch: 400/1000,Cost:0.045300\n",
            "Epoch: 500/1000,Cost:0.037261\n",
            "Epoch: 600/1000,Cost:0.031673\n",
            "Epoch: 700/1000,Cost:0.027556\n",
            "Epoch: 800/1000,Cost:0.024394\n",
            "Epoch: 900/1000,Cost:0.021888\n",
            "Epoch:1000/1000,Cost:0.019852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5IKlSLhAKho"
      },
      "source": [
        "Training with F.binary_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n77K38015c5a",
        "outputId": "4f3c72ec-cd31-4ba6-a993-56e45da6ef23"
      },
      "source": [
        "#initialize the model\n",
        "W=torch.zeros((2,1),requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "#set the optimizer\n",
        "optimizer=optim.SGD([W,b],lr=1)\n",
        "#loop of the epochs\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "    \n",
        "#hypothesis and cost\n",
        "    hypothesis2=torch.sigmoid(x_train.matmul(W)+b)\n",
        "    cost=F.binary_cross_entropy(hypothesis2,y_train)\n",
        "#the improvement of the cost into H(x)\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "#print per 100 \n",
        "    if epoch%100==0:\n",
        "       print('Epoch:{:4d}/{},Cost:{:.6f}'.format(epoch,nb_epochs,cost.item()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0/1000,Cost:0.693147\n",
            "Epoch: 100/1000,Cost:0.134722\n",
            "Epoch: 200/1000,Cost:0.080643\n",
            "Epoch: 300/1000,Cost:0.057900\n",
            "Epoch: 400/1000,Cost:0.045300\n",
            "Epoch: 500/1000,Cost:0.037261\n",
            "Epoch: 600/1000,Cost:0.031672\n",
            "Epoch: 700/1000,Cost:0.027556\n",
            "Epoch: 800/1000,Cost:0.024394\n",
            "Epoch: 900/1000,Cost:0.021888\n",
            "Epoch:1000/1000,Cost:0.019852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV-reoR_AwE2"
      },
      "source": [
        "Loading Real Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd4kKX7DAuQP"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "GKZ9h90BAuTm",
        "outputId": "9a158fa7-050c-4786-9776-cda59e1c6d8b"
      },
      "source": [
        "import pandas as pd\n",
        "data1=pd.read_csv('data-03_2-diabetes.csv', error_bad_lines=False)  \n",
        "\n",
        "data=pd.DataFrame(data1)\n",
        "data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.294118</td>\n",
              "      <td>0.487437</td>\n",
              "      <td>0.180328</td>\n",
              "      <td>-0.292929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001490</td>\n",
              "      <td>-0.531170</td>\n",
              "      <td>-0.033333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.882353</td>\n",
              "      <td>-0.145729</td>\n",
              "      <td>0.081967</td>\n",
              "      <td>-0.414141</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.207153</td>\n",
              "      <td>-0.766866</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.058824</td>\n",
              "      <td>0.839196</td>\n",
              "      <td>0.049180</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.305514</td>\n",
              "      <td>-0.492741</td>\n",
              "      <td>-0.633333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.882353</td>\n",
              "      <td>-0.105528</td>\n",
              "      <td>0.081967</td>\n",
              "      <td>-0.535354</td>\n",
              "      <td>-0.777778</td>\n",
              "      <td>-0.162444</td>\n",
              "      <td>-0.923997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.376884</td>\n",
              "      <td>-0.344262</td>\n",
              "      <td>-0.292929</td>\n",
              "      <td>-0.602837</td>\n",
              "      <td>0.284650</td>\n",
              "      <td>0.887276</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.015075</td>\n",
              "      <td>0.245902</td>\n",
              "      <td>-0.030303</td>\n",
              "      <td>-0.574468</td>\n",
              "      <td>-0.019374</td>\n",
              "      <td>-0.920581</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>-0.764706</td>\n",
              "      <td>0.226131</td>\n",
              "      <td>0.147541</td>\n",
              "      <td>-0.454545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.096870</td>\n",
              "      <td>-0.776260</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>-0.411765</td>\n",
              "      <td>0.216080</td>\n",
              "      <td>0.180328</td>\n",
              "      <td>-0.535354</td>\n",
              "      <td>-0.735225</td>\n",
              "      <td>-0.219076</td>\n",
              "      <td>-0.857387</td>\n",
              "      <td>-0.700000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>-0.882353</td>\n",
              "      <td>0.266332</td>\n",
              "      <td>-0.016393</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.102832</td>\n",
              "      <td>-0.768574</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>-0.882353</td>\n",
              "      <td>-0.065327</td>\n",
              "      <td>0.147541</td>\n",
              "      <td>-0.373737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.093890</td>\n",
              "      <td>-0.797609</td>\n",
              "      <td>-0.933333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>759 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3  ...         5         6         7  8\n",
              "0   -0.294118  0.487437  0.180328 -0.292929  ...  0.001490 -0.531170 -0.033333  0\n",
              "1   -0.882353 -0.145729  0.081967 -0.414141  ... -0.207153 -0.766866 -0.666667  1\n",
              "2   -0.058824  0.839196  0.049180  0.000000  ... -0.305514 -0.492741 -0.633333  0\n",
              "3   -0.882353 -0.105528  0.081967 -0.535354  ... -0.162444 -0.923997  0.000000  1\n",
              "4    0.000000  0.376884 -0.344262 -0.292929  ...  0.284650  0.887276 -0.600000  0\n",
              "..        ...       ...       ...       ...  ...       ...       ...       ... ..\n",
              "754  0.176471  0.015075  0.245902 -0.030303  ... -0.019374 -0.920581  0.400000  1\n",
              "755 -0.764706  0.226131  0.147541 -0.454545  ...  0.096870 -0.776260 -0.800000  1\n",
              "756 -0.411765  0.216080  0.180328 -0.535354  ... -0.219076 -0.857387 -0.700000  1\n",
              "757 -0.882353  0.266332 -0.016393  0.000000  ... -0.102832 -0.768574 -0.133333  0\n",
              "758 -0.882353 -0.065327  0.147541 -0.373737  ... -0.093890 -0.797609 -0.933333  1\n",
              "\n",
              "[759 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPmhDtq_AuZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494787cc-5075-4c2f-fe2f-59abe2694116"
      },
      "source": [
        "df=np.array(data)\n",
        "df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.294118 ,  0.487437 ,  0.180328 , ..., -0.53117  , -0.0333333,\n",
              "         0.       ],\n",
              "       [-0.882353 , -0.145729 ,  0.0819672, ..., -0.766866 , -0.666667 ,\n",
              "         1.       ],\n",
              "       [-0.0588235,  0.839196 ,  0.0491803, ..., -0.492741 , -0.633333 ,\n",
              "         0.       ],\n",
              "       ...,\n",
              "       [-0.411765 ,  0.21608  ,  0.180328 , ..., -0.857387 , -0.7      ,\n",
              "         1.       ],\n",
              "       [-0.882353 ,  0.266332 , -0.0163934, ..., -0.768574 , -0.133333 ,\n",
              "         0.       ],\n",
              "       [-0.882353 , -0.0653266,  0.147541 , ..., -0.797609 , -0.933333 ,\n",
              "         1.       ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j89l8SYMAub1"
      },
      "source": [
        "x_data=df[:,0:-1]\n",
        "y_data=df[:,[-1]]\n",
        "x_train=torch.FloatTensor(x_data)\n",
        "y_train=torch.FloatTensor(y_data)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MhKIVnsMczv",
        "outputId": "724cfd96-7c6b-4f9d-b328-f5e3e1320c24"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([759, 8]), torch.Size([759, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO9UH7HuAueT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ef6f10-e869-420c-b6e9-b006003393da"
      },
      "source": [
        "print(x_train[:5])\n",
        "print(y_train[:5])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2941,  0.4874,  0.1803, -0.2929,  0.0000,  0.0015, -0.5312, -0.0333],\n",
            "        [-0.8824, -0.1457,  0.0820, -0.4141,  0.0000, -0.2072, -0.7669, -0.6667],\n",
            "        [-0.0588,  0.8392,  0.0492,  0.0000,  0.0000, -0.3055, -0.4927, -0.6333],\n",
            "        [-0.8824, -0.1055,  0.0820, -0.5354, -0.7778, -0.1624, -0.9240,  0.0000],\n",
            "        [ 0.0000,  0.3769, -0.3443, -0.2929, -0.6028,  0.2846,  0.8873, -0.6000]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BN6m4-XAuxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f7672f-df75-414e-aed2-8c7a00fd0989"
      },
      "source": [
        "#initialize the model\n",
        "W=torch.zeros((8,1),requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "#set the optimizer\n",
        "optimizer=optim.SGD([W,b],lr=1)\n",
        "nb_epochs=100\n",
        "for epoch in range(nb_epochs+1):\n",
        "#calculate cost and hypothesis\n",
        "    hypothesis=torch.sigmoid(x_train.matmul(W)+b)\n",
        "    cost=-(y_train*torch.log(hypothesis)+(1-y_train)*torch.log(1-hypothesis)).mean()\n",
        "#improve the cost\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "#print the output per 10\n",
        "    if epoch%10==0:\n",
        "       print(\"Epoch:{:4d}/{}, Cost:{:.6f}\".format(epoch,nb_epochs,cost.item()))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0/100, Cost:0.693147\n",
            "Epoch:  10/100, Cost:0.572727\n",
            "Epoch:  20/100, Cost:0.539493\n",
            "Epoch:  30/100, Cost:0.519708\n",
            "Epoch:  40/100, Cost:0.507066\n",
            "Epoch:  50/100, Cost:0.498539\n",
            "Epoch:  60/100, Cost:0.492549\n",
            "Epoch:  70/100, Cost:0.488209\n",
            "Epoch:  80/100, Cost:0.484985\n",
            "Epoch:  90/100, Cost:0.482543\n",
            "Epoch: 100/100, Cost:0.480661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeKi7-ewNVg0"
      },
      "source": [
        "Training with Real Data using F.binary_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7W6vtgRAu1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40901ecd-0740-4f82-94c4-cc124272f626"
      },
      "source": [
        "#initialize the model\n",
        "W=torch.zeros((8,1),requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "#set the optimizer\n",
        "optimizer=optim.SGD([W,b],lr=1)\n",
        "nb_epochs=100\n",
        "for epoch in range(nb_epochs+1):\n",
        "#calculate cost and hypothesis\n",
        "    hypothesis=torch.sigmoid(x_train.matmul(W)+b)\n",
        "    cost=F.binary_cross_entropy(hypothesis,y_train)\n",
        "#improve the cost\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "#print the output per 10\n",
        "    if epoch%10==0:\n",
        "       print(\"Epoch:{:4d}/{}, Cost:{:.6f}\".format(epoch,nb_epochs,cost.item()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0/100, Cost:0.693147\n",
            "Epoch:  10/100, Cost:0.572727\n",
            "Epoch:  20/100, Cost:0.539493\n",
            "Epoch:  30/100, Cost:0.519708\n",
            "Epoch:  40/100, Cost:0.507066\n",
            "Epoch:  50/100, Cost:0.498539\n",
            "Epoch:  60/100, Cost:0.492549\n",
            "Epoch:  70/100, Cost:0.488209\n",
            "Epoch:  80/100, Cost:0.484985\n",
            "Epoch:  90/100, Cost:0.482543\n",
            "Epoch: 100/100, Cost:0.480661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viPuen7GNHb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7743351c-d0a1-489d-9925-1f9cffefab63"
      },
      "source": [
        "hypothesis = torch.sigmoid(x_train.matmul(W)+b)\n",
        "print(hypothesis[:5])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4103],\n",
            "        [0.9242],\n",
            "        [0.2300],\n",
            "        [0.9411],\n",
            "        [0.1772]], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrhvoooyNHfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a481b3f8-4bbd-46a5-9040-82ff1df6f3e2"
      },
      "source": [
        "prediction= hypothesis >= torch.FloatTensor([0.5])\n",
        " \n",
        "print(prediction[:5])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[False],\n",
            "        [ True],\n",
            "        [False],\n",
            "        [ True],\n",
            "        [False]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh5wcKpEsj-y",
        "outputId": "862bd5be-9e94-4111-996f-8a44df04a595"
      },
      "source": [
        "prediction=torch.gt(prediction, 0).int()\n",
        "print(torch.gt(prediction, 0).int()[:5])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0]], dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uDDQFguknVH",
        "outputId": "1a2f5379-b3e2-4c69-b12d-97ef0a13a13f"
      },
      "source": [
        "print(prediction[:5])\n",
        "print(y_train[:5])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0]], dtype=torch.int32)\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWv771qsknYX",
        "outputId": "27dc3711-3a15-4f62-cea4-42226ebe6094"
      },
      "source": [
        "correct_prediction =prediction.float() == y_train\n",
        "correct_prediction=torch.gt(correct_prediction,0).int()\n",
        "print(correct_prediction[:5])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1]], dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pm-5j7sknbb",
        "outputId": "665d18dc-a91a-4680-c912-b57d86323d22"
      },
      "source": [
        "accuracy=correct_prediction.sum().item()/len(correct_prediction)\n",
        "print('The model has the accuracy of {:2.2f}% for the training set.'.format(accuracy*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has the accuracy of 76.68% for the training set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9McBdaJus2H"
      },
      "source": [
        "Optional: High-level Implementation with nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrZQJuZBknef"
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "      def __init__(self):\n",
        "          super().__init__()\n",
        "          self.linear=nn.Linear(8,1)\n",
        "          self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "      def forward(self,x):\n",
        "          return self.sigmoid(self.linear(x))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqG3GoUGkniG"
      },
      "source": [
        "model=BinaryClassifier()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_csQA6h2knko",
        "outputId": "c00dd6ca-f9f6-4cc1-e6d2-8f8c64e80f20"
      },
      "source": [
        "#initialize the model\n",
        "\n",
        "#set the optimizer\n",
        "optimizer=optim.SGD(model.parameters(),lr=1)\n",
        "nb_epochs=100\n",
        "for epoch in range(nb_epochs+1):\n",
        "#calculate cost and hypothesis\n",
        "    hypothesis=model(x_train)\n",
        "    cost=F.binary_cross_entropy(hypothesis,y_train)\n",
        "#improve the cost\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "#print the output per 10\n",
        "    if epoch%10==0:\n",
        "       print(\"Epoch:{:4d}/{}, Cost:{:.6f}\".format(epoch,nb_epochs,cost.item()))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0/100, Cost:0.670614\n",
            "Epoch:  10/100, Cost:0.576439\n",
            "Epoch:  20/100, Cost:0.540851\n",
            "Epoch:  30/100, Cost:0.520186\n",
            "Epoch:  40/100, Cost:0.507220\n",
            "Epoch:  50/100, Cost:0.498581\n",
            "Epoch:  60/100, Cost:0.492561\n",
            "Epoch:  70/100, Cost:0.488220\n",
            "Epoch:  80/100, Cost:0.485006\n",
            "Epoch:  90/100, Cost:0.482574\n",
            "Epoch: 100/100, Cost:0.480701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEcDMLj_knoW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiaQ7SfyNHiA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sIDvrY6NHlE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}